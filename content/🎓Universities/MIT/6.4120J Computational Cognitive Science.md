---
tags: [course]
ctime: "2024-04-17T23:06:24"
mstime: "2024-04-17T23:06:24"

level: undergraduate
subject: 
university: mit
completion: closed
percentage: 0
prereq: "<ðŸŽ“Universities/MIT/6.3700 Introduction to Probability> , <ðŸŽ“Universities/MIT/6.3800 Introduction to Inference> , <ðŸŽ“Universities/MIT/9.40 Introduction to Neural Computation> , <ðŸŽ“Universities/MIT/18.05 Introduction to Probability and Statistics> , <ðŸŽ“Universities/MIT/6.3900 Introduction to Machine Learning> , or permission of instructor"
coreq: "None."
---

catalog [6.4120[J]](http://student.mit.edu/catalog/m6d.html#6.4120), [9.66[J]](http://student.mit.edu/catalog/m9b.html#9.66), [9.660](http://student.mit.edu/catalog/m9b.html#9.660)

<span style="display: block; padding: 15px; background-color: rgb(100, 100, 100, 0.2);"><font id="m_prereq3413_0" style="display: block; font-family: Arial, sans-serif; font-weight: bold; padding: 5px">Prerequisites</font><br><span id="prereq3413_0">[[ðŸŽ“Universities/MIT/6.3700 Introduction to Probability | 6.3700]] , [[ðŸŽ“Universities/MIT/6.3800 Introduction to Inference | 6.3800]] , [[ðŸŽ“Universities/MIT/9.40 Introduction to Neural Computation | 9.40]] , [[ðŸŽ“Universities/MIT/18.05 Introduction to Probability and Statistics | 18.05]] , [[ðŸŽ“Universities/MIT/6.3900 Introduction to Machine Learning | 6.3900]] , or permission of instructor</span></span>
<span style="display: block; padding: 15px; background-color: rgb(100, 100, 100, 0.2);"><font id="m_coreq3413_0" style="display: block; font-family: Arial, sans-serif; font-weight: bold; padding: 5px">Corequisites</font><br><span id="coreq3413_0">None.</span></span>

<font style="">Description:</font>
<font style="color: grey; font-size: 0.8rem;">Introduction to computational theories of human cognition. Focus on principles of inductive learning and inference, and the representation of knowledge. Computational frameworks covered include Bayesian and hierarchical Bayesian models; probabilistic graphical models; nonparametric statistical models and the Bayesian Occam's razor; sampling algorithms for approximate learning and inference; and probabilistic models defined over structured representations such as first-order logic, grammars, or relational schemas. Applications to understanding core aspects of cognition, such as concept learning and categorization, causal reasoning, theory formation, language acquisition, and social inference. Graduate students complete a final project.</font>



---

<< HELLO, WORLD >>
