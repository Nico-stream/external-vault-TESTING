---
tags: [course]
ctime: "2024-04-17T23:06:24"
mstime: "2024-04-17T23:06:24"

level: graduate
subject: 
university: mit
completion: closed
percentage: 0
prereq: "<ðŸŽ“Universities/MIT/6.3700 Introduction to Probability> , <ðŸŽ“Universities/MIT/6.3800 Introduction to Inference> , or <ðŸŽ“Universities/MIT/15.085J Fundamentals of Probability>"
coreq: "None."
---

catalog [6.7800](http://student.mit.edu/catalog/m6c.html#6.7800)

<span style="display: block; padding: 15px; background-color: rgb(100, 100, 100, 0.2);"><font id="m_prereq3400_0" style="display: block; font-family: Arial, sans-serif; font-weight: bold; padding: 5px">Prerequisites</font><br><span id="prereq3400_0">[[ðŸŽ“Universities/MIT/6.3700 Introduction to Probability | 6.3700]] , [[ðŸŽ“Universities/MIT/6.3800 Introduction to Inference | 6.3800]] , or [[ðŸŽ“Universities/MIT/15.085J Fundamentals of Probability | 6.7700]]</span></span>
<span style="display: block; padding: 15px; background-color: rgb(100, 100, 100, 0.2);"><font id="m_coreq3400_0" style="display: block; font-family: Arial, sans-serif; font-weight: bold; padding: 5px">Corequisites</font><br><span id="coreq3400_0">None.</span></span>

<font style="">Description:</font>
<font style="color: grey; font-size: 0.8rem;">Introduction to principles of Bayesian and non-Bayesian statistical inference. Hypothesis testing and parameter estimation, sufficient statistics; exponential families. EM agorithm. Log-loss inference criterion, entropy and model capacity. Kullback-Leibler distance and information geometry. Asymptotic analysis and large deviations theory. Model order estimation; nonparametric statistics. Computational issues and approximation techniques; Monte Carlo methods. Selected topics such as universal inference and learning, and universal features and neural networks.</font>



---

<< HELLO, WORLD >>
